//===------------------------------------------------------------*- C++ -*-===//
//
//             Ripples: A C++ Library for Influence Maximization
//                  Marco Minutoli <marco.minutoli@pnnl.gov>
//                   Pacific Northwest National Laboratory
//
//===----------------------------------------------------------------------===//
//
// Copyright (c) 2019, Battelle Memorial Institute
//
// Battelle Memorial Institute (hereinafter Battelle) hereby grants permission
// to any person or entity lawfully obtaining a copy of this software and
// associated documentation files (hereinafter “the Software”) to redistribute
// and use the Software in source and binary forms, with or without
// modification.  Such person or entity may use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and may permit
// others to do so, subject to the following conditions:
//
// 1. Redistributions of source code must retain the above copyright notice,
//    this list of conditions and the following disclaimers.
//
// 2. Redistributions in binary form must reproduce the above copyright notice,
//    this list of conditions and the following disclaimer in the documentation
//    and/or other materials provided with the distribution.
//
// 3. Other than as used herein, neither the name Battelle Memorial Institute or
//    Battelle may be used in any form whatsoever without the express written
//    consent of Battelle.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL BATTELLE OR CONTRIBUTORS BE LIABLE FOR ANY
// DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
// (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
// LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
// ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
//
//===----------------------------------------------------------------------===//

#ifndef RIPPLES_IMM_H
#define RIPPLES_IMM_H

#include <cmath>
#include <cstddef>
#include <limits>
#include <unordered_map>
#include <vector>

#include "nlohmann/json.hpp"
#include "trng/lcg64.hpp"
#include "trng/uniform01_dist.hpp"
#include "trng/uniform_int_dist.hpp"

#include "ripples/configuration.h"
#include "ripples/find_most_influential.h"
#include "ripples/generate_rrr_sets.h"
#include "ripples/imm_execution_record.h"
#include "ripples/tim.h"
#include "ripples/utility.h"

#include "ripples/streaming_rrr_generator.h"

#define CUDA_PROFILE 0

namespace ripples {

//! The IMM algorithm configuration descriptor.
struct IMMConfiguration : public TIMConfiguration {
  size_t streaming_workers{0};
  size_t streaming_gpu_workers{0};
  size_t seed_select_max_workers{std::numeric_limits<size_t>::max()};
  size_t seed_select_max_gpu_workers{0};
  std::string gpu_mapping_string{""};
  std::unordered_map<size_t, size_t> worker_to_gpu;

  //! \brief Add command line options to configure IMM.
  //!
  //! \param app The command-line parser object.
  void addCmdOptions(CLI::App &app) {
    TIMConfiguration::addCmdOptions(app);
    app.add_option(
           "--streaming-gpu-workers", streaming_gpu_workers,
           "The number of GPU workers for the CPU+GPU streaming engine.")
        ->group("Streaming-Engine Options");
    app.add_option("--streaming-gpu-mapping", gpu_mapping_string,
                   "A comma-separated set of OpenMP numbers for GPU workers.")
        ->group("Streaming-Engine Options");
    app.add_option("--seed-select-max-workers", seed_select_max_workers,
                   "The max number of workers for seed selection.")
        ->group("Streaming-Engine Options");
    app.add_option("--seed-select-max-gpu-workers", seed_select_max_gpu_workers,
                   "The max number of GPU workers for seed selection.")
        ->group("Streaming-Engine Options");
  }
};

//! Retrieve the configuration parsed from command line.
//! \return the configuration parsed from command line.
ToolConfiguration<ripples::IMMConfiguration> configuration();

//! Approximate logarithm of n chose k.
//! \param n
//! \param k
//! \return an approximation of log(n choose k).
inline double logBinomial(size_t n, size_t k) {
  return n * log(n) - k * log(k) - (n - k) * log(n - k);
}

//! Compute ThetaPrime.
//!
//! \tparam execution_tag The execution policy
//!
//! \param x The index of the current iteration.
//! \param epsilonPrime Parameter controlling the approximation factor.
//! \param l Parameter usually set to 1.
//! \param k The size of the seed set.
//! \param num_nodes The number of nodes in the input graph.
template <typename execution_tag>
ssize_t ThetaPrime(ssize_t x, double epsilonPrime, double l, size_t k,
                   size_t num_nodes, execution_tag &&) {
  k = std::min(k, num_nodes/2);
  return (2 + 2. / 3. * epsilonPrime) *
         (l * std::log(num_nodes) + logBinomial(num_nodes, k) +
          std::log(std::log2(num_nodes))) *
         std::pow(2.0, x) / (epsilonPrime * epsilonPrime);
}

//! Compute Theta.
//!
//! \param epsilon Parameter controlling the approximation factor.
//! \param l Parameter usually set to 1.
//! \param k The size of the seed set.
//! \param LB The estimate of the lower bound.
//! \param num_nodes The number of nodes in the input graph.
inline size_t Theta(double epsilon, double l, size_t k, double LB,
                    size_t num_nodes) {
  if (LB == 0) return 0;

  k = std::min(k, num_nodes/2);
  double term1 = 0.6321205588285577;  // 1 - 1/e
  double alpha = sqrt(l * std::log(num_nodes) + std::log(2));
  double beta = sqrt(term1 * (logBinomial(num_nodes, k) +
                              l * std::log(num_nodes) + std::log(2)));
  double lamdaStar = 2 * num_nodes * (term1 * alpha + beta) *
                     (term1 * alpha + beta) * pow(epsilon, -2);

  // std::cout << "#### " << lamdaStar << " / " << LB << " = " << lamdaStar / LB << std::endl;
  return lamdaStar / LB;
}

//! Collect a set of Random Reverse Reachable set.
//!
//! \tparam GraphTy The type of the input graph.
//! \tparam RRRGeneratorTy The type of the RRR generator.
//! \tparam diff_model_tag Type-Tag to selecte the diffusion model.
//! \tparam execution_tag Type-Tag to select the execution policy.
//!
//! \param G The input graph.  The graph is transoposed.
//! \param k The size of the seed set.
//! \param epsilon The parameter controlling the approximation guarantee.
//! \param l Parameter usually set to 1.
//! \param generator The rrr sets generator.
//! \param record Data structure storing timing and event counts.
//! \param model_tag The diffusion model tag.
//! \param ex_tag The execution policy tag.
template <typename GraphTy, typename ConfTy, typename RRRGeneratorTy,
          typename diff_model_tag, typename execution_tag>
auto Sampling(const GraphTy &G, const ConfTy &CFG, double l,
              RRRGeneratorTy &generator, IMMExecutionRecord &record,
              diff_model_tag &&model_tag, execution_tag &&ex_tag) {
  using vertex_type = typename GraphTy::vertex_type;
  using ex_time_ms = std::chrono::duration<double, std::milli>;
  size_t k = CFG.k;
  double epsilon = CFG.epsilon;
  int blocks=CFG.q;
  // sqrt(2) * epsilon
  double epsilonPrime = 1.4142135623730951 * epsilon;

  double LB = 0;
  #ifdef ENABLE_MEMKIND
  RRRsetAllocator<vertex_type> allocator(libmemkind::kinds::DAX_KMEM_PREFERRED);
  #else
  RRRsetAllocator<vertex_type> allocator;
  #endif
  std::vector<RRRset<GraphTy>> RR;

  auto xc1 = spdlog::stdout_color_st("xc1:");
  
  auto start = std::chrono::high_resolution_clock::now();
  size_t thetaPrime = 0;
  ex_time_ms elapse;
  size_t mem_use=0, offset=0;
  for (ssize_t x = 1; x < std::log2(G.num_nodes()); ++x) {
    // Equation 9
    ssize_t thetaPrime = ThetaPrime(x, epsilonPrime, l, k, G.num_nodes(),
                                    std::forward<execution_tag>(ex_tag));

    size_t delta = thetaPrime - RR.size();
    record.ThetaPrimeDeltas.push_back(delta);
    size_t delta_block_sum = 0;
    
    int delta_block;
    double vm1,vm2;

    for(int i=0;i<blocks;i++){
      delta_block = delta/blocks;
      auto t0 = std::chrono::high_resolution_clock::now();
      auto timeRRRSets = measure<>::exec_time([&]() {
        RR.insert(RR.end(), delta_block, RRRset<GraphTy>(allocator));

        auto begin = RR.end() - delta_block;
        
        GenerateRRRSets(G, generator, begin, RR.end(), record,
                        std::forward<diff_model_tag>(model_tag),
                        std::forward<execution_tag>(ex_tag));
        
      });
      record.ThetaEstimationGenerateRRR.push_back(timeRRRSets);
      auto t1 = std::chrono::high_resolution_clock::now();
      elapse=t1-t0;
      mem_use=CheckRRRSize(G,RR);
      std::cout<<" gen-rrr.time=("<<elapse.count()<<")ms";
      std::cout<<" RRR-mem-usage="<<mem_use<<" MB"<<std::endl;
      double vm1;
      process_mem_usage(vm1);
    }
    double f;

    auto timeMostInfluential = measure<>::exec_time([&]() {
      auto t2 = std::chrono::high_resolution_clock::now();
      const auto &S =
          FindMostInfluentialSet(G, CFG, RR, record, generator.isGpuEnabled(),
                                 std::forward<execution_tag>(ex_tag));
      auto t3 = std::chrono::high_resolution_clock::now();
      elapse=t3-t2;
      std::cout<<" find-rrr.time=("<<elapse.count()<<")ms"<<std::endl;    
      f = S.first;
    });

    record.ThetaEstimationMostInfluential.push_back(timeMostInfluential);

    xc1->info("$$$ thetaprime={:d} delta={:d} RR.size={:7d} f={:f}",thetaPrime, delta, RR.size(), f);
    if (f >= std::pow(2, -x)) {
      LB = (G.num_nodes() * f) / (1 + epsilonPrime);
      break;
    }
  }

  size_t theta = Theta(epsilon, l, k, LB, G.num_nodes());
  auto end = std::chrono::high_resolution_clock::now();

  record.ThetaEstimationTotal = end - start;

  record.Theta = theta;
  spdlog::get("console")->info("Theta {}", theta);

  record.GenerateRRRSets = measure<>::exec_time([&]() {
    if (theta > RR.size()) {
      size_t final_delta = theta - RR.size();
      int delta_block;
      for(int i=0;i<blocks;i++){
        delta_block = final_delta/blocks;
        RR.insert(RR.end(), delta_block, RRRset<GraphTy>(allocator));

        auto begin = RR.end() - delta_block;
        auto t4 = std::chrono::high_resolution_clock::now();
        GenerateRRRSets(G, generator, begin, RR.end(), record,
                        std::forward<diff_model_tag>(model_tag),
                        std::forward<execution_tag>(ex_tag));
        auto t5 = std::chrono::high_resolution_clock::now();
        elapse=t5-t4;
        mem_use=CheckRRRSize(G,RR);
        std::cout<<" extra-gen-rrr.time=("<<elapse.count()<<")ms";
        std::cout<<" RRR-mem-usage="<<mem_use<<" MB"<<std::endl;
        double vm1;
        process_mem_usage(vm1);
      }
    }
  });
  return RR;
}

template <typename GraphTy, typename ConfTy, typename RRRGeneratorTy,
          typename diff_model_tag, typename execution_tag>
auto SamplingIO(const GraphTy &G, const ConfTy &CFG, double l,
              RRRGeneratorTy &generator, IMMExecutionRecord &record,
              diff_model_tag &&model_tag, execution_tag &&ex_tag) {
  using vertex_type = typename GraphTy::vertex_type;
  using ex_time_ms = std::chrono::duration<double, std::milli>;
  size_t k = CFG.k;
  double epsilon = CFG.epsilon;
  int blocks=CFG.q;
  // sqrt(2) * epsilon
  double epsilonPrime = 1.4142135623730951 * epsilon;

  double LB = 0;
  #ifdef ENABLE_MEMKIND
  RRRsetAllocator<vertex_type> allocator(libmemkind::kinds::DAX_KMEM_PREFERRED);
  #else
  RRRsetAllocator<vertex_type> allocator;
  #endif
  std::vector<RRRset<GraphTy>> RR;

  auto xc1 = spdlog::stdout_color_st("xc1:");
  
  auto start = std::chrono::high_resolution_clock::now();
  size_t thetaPrime = 0;
  ex_time_ms elapse;
  size_t mem_use=0, offset=0;
  for (ssize_t x = 1; x < std::log2(G.num_nodes()); ++x) {
    // Equation 9
    ssize_t thetaPrime = ThetaPrime(x, epsilonPrime, l, k, G.num_nodes(),
                                    std::forward<execution_tag>(ex_tag));

    size_t delta = thetaPrime - RR.size();
    record.ThetaPrimeDeltas.push_back(delta);
    size_t delta_block_sum = 0;
    
    int delta_block;
    double vm1,vm2;

    for(int i=0;i<blocks;i++){
      delta_block = delta/blocks;
      auto t0 = std::chrono::high_resolution_clock::now();
      auto timeRRRSets = measure<>::exec_time([&]() {
        RR.insert(RR.end(), delta_block, RRRset<GraphTy>(allocator));

        auto begin = RR.end() - delta_block;
        
        GenerateRRRSets(G, generator, begin, RR.end(), record,
                        std::forward<diff_model_tag>(model_tag),
                        std::forward<execution_tag>(ex_tag));
        
      });
      record.ThetaEstimationGenerateRRR.push_back(timeRRRSets);
      auto t1 = std::chrono::high_resolution_clock::now();
      elapse=t1-t0;
      mem_use=CheckRRRSize(G,RR);
      std::cout<<" gen-rrr.time=("<<elapse.count()<<")ms";
      std::cout<<" RRR-mem-usage="<<mem_use<<" MB"<<std::endl;
      double vm1;
      process_mem_usage(vm1);
      if(CFG.memlimit<vm1){
        offset=(size_t)RR.size()*CFG.memlimit/vm1;
        std::cout<<"write block("<<i<<") to SSD"<<std::endl;
        DumpRRRSets(G,RR,offset);
        ReadRRRSets(G); //no read, dump RRR to test on Ookami
        if(i<blocks-1){
          RR.clear();
          RR.shrink_to_fit();
        }  
      }
    }
    double f;

    auto timeMostInfluential = measure<>::exec_time([&]() {
      auto t2 = std::chrono::high_resolution_clock::now();
      const auto &S =
          FindMostInfluentialSet(G, CFG, RR, record, generator.isGpuEnabled(),
                                 std::forward<execution_tag>(ex_tag));
      auto t3 = std::chrono::high_resolution_clock::now();
      elapse=t3-t2;
      std::cout<<" find-rrr.time=("<<elapse.count()<<")ms"<<std::endl;
      f = S.first;
    });

    record.ThetaEstimationMostInfluential.push_back(timeMostInfluential);

    xc1->info("$$$ thetaprime={:d} delta={:d} RR.size={:7d} f={:f}",thetaPrime, delta, RR.size(), f);
    if (f >= std::pow(2, -x)) {
      LB = (G.num_nodes() * f) / (1 + epsilonPrime);
      break;
    }
  }

  size_t theta = Theta(epsilon, l, k, LB, G.num_nodes());
  auto end = std::chrono::high_resolution_clock::now();

  record.ThetaEstimationTotal = end - start;

  record.Theta = theta;
  spdlog::get("console")->info("Theta {}", theta);

  record.GenerateRRRSets = measure<>::exec_time([&]() {
    if (theta > RR.size()) {
      size_t final_delta = theta - RR.size();
      int delta_block;
      for(int i=0;i<blocks;i++){
        delta_block = final_delta/blocks;
        RR.insert(RR.end(), delta_block, RRRset<GraphTy>(allocator));

        auto begin = RR.end() - delta_block;
        auto t4 = std::chrono::high_resolution_clock::now();
        GenerateRRRSets(G, generator, begin, RR.end(), record,
                        std::forward<diff_model_tag>(model_tag),
                        std::forward<execution_tag>(ex_tag));
        auto t5 = std::chrono::high_resolution_clock::now();
        elapse=t5-t4;
        mem_use=CheckRRRSize(G,RR);
        std::cout<<" extra-gen-rrr.time=("<<elapse.count()<<")ms";
        std::cout<<" RRR-mem-usage="<<mem_use<<" MB"<<std::endl;
        double vm1;
        process_mem_usage(vm1);
        if(CFG.memlimit<vm1){
          offset=(size_t)RR.size()*CFG.memlimit/vm1;
          DumpRRRSets(G,RR,offset);
          ReadRRRSets(G); //no read, dump RRR to test on Ookami
          if(i<blocks-1){
            RR.clear();
            RR.shrink_to_fit();
          }
        }
      }
    }
  });
  return RR;
}

template <typename GraphTy, typename ConfTy, typename RRRGeneratorTy,
          typename diff_model_tag>
auto Sampling(const GraphTy &G, const ConfTy &CFG, double l,
              RRRGeneratorTy &generator, IMMExecutionRecord &record,
              diff_model_tag &&model_tag, sequential_tag &&ex_tag) {
  using vertex_type = typename GraphTy::vertex_type;
  size_t k = CFG.k;
  double epsilon = CFG.epsilon;

  // sqrt(2) * epsilon
  double epsilonPrime = 1.4142135623730951 * epsilon;

  double LB = 0;
  #ifdef ENABLE_MEMKIND
  RRRsetAllocator<vertex_type> allocator(libmemkind::kinds::DAX_KMEM_PREFERRED);
  #else
  RRRsetAllocator<vertex_type> allocator;
  #endif
  std::vector<RRRset<GraphTy>> RR;

  auto start = std::chrono::high_resolution_clock::now();
  size_t thetaPrime = 0;
  for (ssize_t x = 1; x < std::log2(G.num_nodes()); ++x) {
    // Equation 9
    ssize_t thetaPrime = ThetaPrime(x, epsilonPrime, l, k, G.num_nodes(),
                                    std::forward<sequential_tag>(ex_tag));

    size_t delta = thetaPrime - RR.size();
    record.ThetaPrimeDeltas.push_back(delta);

    auto timeRRRSets = measure<>::exec_time([&]() {
      RR.insert(RR.end(), delta, RRRset<GraphTy>(allocator));

      auto begin = RR.end() - delta;

      GenerateRRRSets(G, generator, begin, RR.end(), record,
                      std::forward<diff_model_tag>(model_tag),
                      std::forward<sequential_tag>(ex_tag));
    });
    record.ThetaEstimationGenerateRRR.push_back(timeRRRSets);

    double f;

    auto timeMostInfluential = measure<>::exec_time([&]() {
      const auto &S = FindMostInfluentialSet(
          G, CFG, RR, record, false, std::forward<sequential_tag>(ex_tag));

      f = S.first;
    });

    record.ThetaEstimationMostInfluential.push_back(timeMostInfluential);

    if (f >= std::pow(2, -x)) {
      LB = (G.num_nodes() * f) / (1 + epsilonPrime);
      break;
    }
  }

  size_t theta = Theta(epsilon, l, k, LB, G.num_nodes());
  auto end = std::chrono::high_resolution_clock::now();

  record.ThetaEstimationTotal = end - start;

  record.Theta = theta;

  record.GenerateRRRSets = measure<>::exec_time([&]() {
    if (theta > RR.size()) {
      size_t final_delta = theta - RR.size();
      RR.insert(RR.end(), final_delta, RRRset<GraphTy>(allocator));

      auto begin = RR.end() - final_delta;

      GenerateRRRSets(G, generator, begin, RR.end(), record,
                      std::forward<diff_model_tag>(model_tag),
                      std::forward<sequential_tag>(ex_tag));
    }
  });

  return RR;
}

//! The IMM algroithm for Influence Maximization
//!
//! \tparam GraphTy The type of the input graph.
//! \tparam ConfTy The configuration type.
//! \tparam PRNG The type of the parallel random number generator.
//! \tparam diff_model_tag Type-Tag to selecte the diffusion model.
//!
//! \param G The input graph.  The graph is transoposed.
//! \param CFG The configuration.
//! \param l Parameter usually set to 1.
//! \param gen The parallel random number generator.
//! \param model_tag The diffusion model tag.
//! \param ex_tag The execution policy tag.
template <typename GraphTy, typename ConfTy, typename PRNG,
          typename diff_model_tag>
auto IMM(const GraphTy &G, const ConfTy &CFG, double l, PRNG &gen,
         IMMExecutionRecord &record, diff_model_tag &&model_tag,
         sequential_tag &&ex_tag) {
  using vertex_type = typename GraphTy::vertex_type;
  size_t k = CFG.k;
  double epsilon = CFG.epsilon;

  std::vector<trng::lcg64> generator(1, gen);

  l = l * (1 + 1 / std::log2(G.num_nodes()));

  auto R = Sampling(G, CFG, l, generator, record,
                    std::forward<diff_model_tag>(model_tag),
                    std::forward<sequential_tag>(ex_tag));

#if CUDA_PROFILE
  auto logst = spdlog::stdout_color_st("IMM-profile");
  std::vector<size_t> rrr_sizes;
  for (auto &rrr_set : R) rrr_sizes.push_back(rrr_set.size());
  print_profile_counter(logst, rrr_sizes, "RRR sizes");
#endif

  auto start = std::chrono::high_resolution_clock::now();
  const auto &S = FindMostInfluentialSet(G, CFG, R, record, false,
                                         std::forward<sequential_tag>(ex_tag));
  auto end = std::chrono::high_resolution_clock::now();

  record.FindMostInfluentialSet = end - start;

  return S.second;
}

//! The IMM algroithm for Influence Maximization
//!
//! \tparam GraphTy The type of the input graph.
//! \tparam ConfTy The configuration type
//! \tparam PRNG The type of the parallel random number generator.
//! \tparam diff_model_tag Type-Tag to selecte the diffusion model.
//! \tparam execution_tag Type-Tag to select the execution policy.
//!
//! \param G The input graph.  The graph is transoposed.
//! \param CFG The configuration.
//! \param l Parameter usually set to 1.
//! \param gen The parallel random number generator.
//! \param model_tag The diffusion model tag.
//! \param ex_tag The execution policy tag.
template <typename GraphTy, typename ConfTy, typename GeneratorTy,
          typename diff_model_tag>
auto IMM(const GraphTy &G, const ConfTy &CFG, double l, GeneratorTy &gen,
         diff_model_tag &&model_tag, omp_parallel_tag &&ex_tag) {
  using vertex_type = typename GraphTy::vertex_type;
  using ex_time_ms = std::chrono::duration<double, std::milli>;
  size_t k = CFG.k;
  double epsilon = CFG.epsilon;
  double vm1,vm2;
  auto &record(gen.execution_record());
  ex_time_ms elapse;
  l = l * (1 + 1 / std::log2(G.num_nodes()));

  auto R =
      Sampling(G, CFG, l, gen, record, std::forward<diff_model_tag>(model_tag),
               std::forward<omp_parallel_tag>(ex_tag));
  
  process_mem_usage(vm1);
  size_t offset=0;
  if(CFG.memlimit<vm1){
    offset=(size_t)R.size()*CFG.memlimit/vm1;
    DumpRRRSets(G,R,offset);
    ReadRRRSets(G); //no read, dump RRR to test on Ookami
  }
  
  process_mem_usage(vm1);
  size_t mem_use=CheckRRRSize(G,R);
  std::cout << "##imm-sampling: " << vm1 << " MB";
  std::cout << " RRR-mem-usage="<<mem_use<<" MB"<<std::endl;
#if CUDA_PROFILE
  auto logst = spdlog::stdout_color_st("IMM-profile");
  std::vector<size_t> rrr_sizes;
  size_t sizeBytes = 0;
  for (auto &rrr_set : R) {
    rrr_sizes.push_back(rrr_set.size());
    sizeBytes += rrr_set.size() * sizeof(rrr_set[0]);
  }
  record.RRRSetSize = sizeBytes;
  print_profile_counter(logst, rrr_sizes, "RRR sizes");
#endif

  auto start = std::chrono::high_resolution_clock::now();
  const auto &S =
      FindMostInfluentialSet(G, CFG, R, record, gen.isGpuEnabled(),
                             std::forward<omp_parallel_tag>(ex_tag));
  auto end = std::chrono::high_resolution_clock::now();
  elapse=end-start;
  std::cout<<" final-find.time=("<<elapse.count()<<")ms"<<std::endl;
  record.FindMostInfluentialSet = end - start;
  process_mem_usage(vm2);
  std::cout << "##imm-select: " << vm2 << " Mb" <<std::endl;     

  start = std::chrono::high_resolution_clock::now();
  size_t total_size = 0;
#pragma omp parallel for reduction(+:total_size)
  for (size_t i = 0; i < R.size(); ++i) {
    total_size += R[i].size() * sizeof(vertex_type);
  }
  record.RRRSetSize = total_size;
  end = std::chrono::high_resolution_clock::now();
  record.Total = end - start;

  auto xc4 = spdlog::stdout_color_st("xc4:");
  xc4->info("$$$ IMM-2 f={:f}", S.first);
  // DumpRRRSets(G,R,0);
  return S.second;
}

}  // namespace ripples

#endif  // RIPPLES_IMM_H
